{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0583c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import ast\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840f2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reliability\n",
    "def get_username(instagram_url):\n",
    "    parsed_url = urlparse(instagram_url)\n",
    "    path_segments = parsed_url.path.strip('/').split('/')\n",
    "    username = path_segments[-1]\n",
    "    return username\n",
    "insta_df = pd.read_csv('../../data/reliability.csv').drop(columns = 'Unnamed: 0').drop_duplicates(subset='username', keep='last')\n",
    "social_media = pd.read_csv('../../data/credibility_with_insta_username.csv').drop(columns = 'Unnamed: 0')\n",
    "cleaned_social_media = social_media[social_media['instagram_uri'].str.contains('instagram', na=False)].reset_index().drop(columns = 'index')\n",
    "cleaned_social_media['username'] = cleaned_social_media['instagram_uri'].apply(get_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be2eca2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>biography</th>\n",
       "      <th>userid</th>\n",
       "      <th>mediacount</th>\n",
       "      <th>followers</th>\n",
       "      <th>followees</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scottwalker</td>\n",
       "      <td>Christian American Husband Father 45th Governo...</td>\n",
       "      <td>586553277</td>\n",
       "      <td>8683</td>\n",
       "      <td>47989</td>\n",
       "      <td>175</td>\n",
       "      <td>True</td>\n",
       "      <td>Scott Walker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newyorkcitizensauditnews</td>\n",
       "      <td>NY Citizens Audit is a Volunteer based group. ...</td>\n",
       "      <td>50346417000</td>\n",
       "      <td>1202</td>\n",
       "      <td>891</td>\n",
       "      <td>460</td>\n",
       "      <td>False</td>\n",
       "      <td>New York Citizens Audit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>steventkirsch</td>\n",
       "      <td>Retired serial entrepreneur. Follow me on stev...</td>\n",
       "      <td>184544694</td>\n",
       "      <td>10</td>\n",
       "      <td>4469</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>Steve Kirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shannonrwatts</td>\n",
       "      <td>üé§ Speaker, author, organizer\\nüôã‚Äç‚ôÄÔ∏è ‚ÄúSummoner o...</td>\n",
       "      <td>24779854</td>\n",
       "      <td>431</td>\n",
       "      <td>129536</td>\n",
       "      <td>2369</td>\n",
       "      <td>True</td>\n",
       "      <td>Shannon Watts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chris_larson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5941863</td>\n",
       "      <td>1138</td>\n",
       "      <td>1743</td>\n",
       "      <td>349</td>\n",
       "      <td>False</td>\n",
       "      <td>Chris Larson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   username  \\\n",
       "0               scottwalker   \n",
       "1  newyorkcitizensauditnews   \n",
       "2             steventkirsch   \n",
       "3             shannonrwatts   \n",
       "4              chris_larson   \n",
       "\n",
       "                                           biography       userid  mediacount  \\\n",
       "0  Christian American Husband Father 45th Governo...    586553277        8683   \n",
       "1  NY Citizens Audit is a Volunteer based group. ...  50346417000        1202   \n",
       "2  Retired serial entrepreneur. Follow me on stev...    184544694          10   \n",
       "3  üé§ Speaker, author, organizer\\nüôã‚Äç‚ôÄÔ∏è ‚ÄúSummoner o...     24779854         431   \n",
       "4                                                NaN      5941863        1138   \n",
       "\n",
       "   followers  followees  is_verified                   source  \n",
       "0      47989        175         True             Scott Walker  \n",
       "1        891        460        False  New York Citizens Audit  \n",
       "2       4469         20        False             Steve Kirsch  \n",
       "3     129536       2369         True            Shannon Watts  \n",
       "4       1743        349        False             Chris Larson  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reliability\n",
    "unique_df = cleaned_social_media[['username', 'source']].drop_duplicates(subset='source', keep='last')\n",
    "merged_df = pd.merge(insta_df, unique_df, on='username', how='inner').reset_index().drop(columns = 'index')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = ['True', 'Mostly True ','Half True ', 'Mostly False', 'False', 'Pants on Fire']\n",
    "score = np.array([10, 8, 6, 4, 2, 0])\n",
    "poli_df = pd.read_csv('../../data/politifact_data.csv')\n",
    "def transform_percentages(col):\n",
    "    return sum(np.array(ast.literal_eval(col.replace('%', '').replace('\\'', '').replace(' ', ',')))/100 * score)\n",
    "poli_df['credibility_score'] = poli_df['percentages'].apply(transform_percentages)\n",
    "poli_df['content'] = poli_df['content'].str.replace(\"‚Äú\", \"\").str.replace(\"‚Äù\",\"\").str.replace(\"\\\"\", '')\n",
    "poli_df = poli_df.rename(columns = {'speaker':'recorder', 'media':'source'})\n",
    "\n",
    "def extract_date(text):\n",
    "    date_pattern = re.compile(r'\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{1,2},\\s\\d{4}\\b')\n",
    "    match = date_pattern.search(text) \n",
    "    if match:\n",
    "        date = match.group()\n",
    "        return date\n",
    "poli_df['publish_time'] = poli_df['when/where'].apply(extract_date)\n",
    "poli_df['content'].head()[0]\n",
    "clean_df = poli_df[['source', 'credibility_score']].drop_duplicates().reset_index().drop(columns = 'index')\n",
    "clean_df.head()\n",
    "import requests\n",
    "def search_wikipedia(query, num_results=15):\n",
    "    endpoint_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'list': 'search',\n",
    "        'srsearch': query,\n",
    "        'srlimit': num_results\n",
    "    }\n",
    "    response = requests.get(endpoint_url, params=params)\n",
    "    data = response.json()\n",
    "    output = []\n",
    "    search_results = data['query']['search']\n",
    "    for result in search_results:\n",
    "        title = result['title']\n",
    "        output.append(title)\n",
    "    return \" \".join(output)\n",
    "def scrape_titles(col):\n",
    "    return search_wikipedia(col, num_results=20)\n",
    "clean_df['source_history'] = clean_df['source'].apply(scrape_titles)\n",
    "# clean_df.to_csv('../../data/credibility.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4d777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('../../data/credibility.csv', index_col=None).drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eece356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>credibility_score</th>\n",
       "      <th>source_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Instagram List of most-followed Instagram acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>5.14</td>\n",
       "      <td>Scott Walker Scott Walker (politician) Scott W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Viral image</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Viral phenomenon Imgur The dress Midjourney Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>1.86</td>\n",
       "      <td>Facebook Facebook 3D Posts Meta Platforms Hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Citizens Audit</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Sovereign citizen movement KPMG BNY Mellon Arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>Freedom Defense Advocates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>United States Army Judge Advocate General's Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>Spike the Romney Attack Dog</td>\n",
       "      <td>8.00</td>\n",
       "      <td>Mitt Romney List of individual dogs January 6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>Log Cabin Republicans</td>\n",
       "      <td>8.00</td>\n",
       "      <td>Log Cabin Republicans Don Korotsky Norte Log C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Sam Brownback</td>\n",
       "      <td>6.50</td>\n",
       "      <td>Sam Brownback Kansas experiment Sam Brownback ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>Obama Girl</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Amber Lee Ettinger Family of Barack Obama Mich...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4700 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           source  credibility_score  \\\n",
       "0                 Instagram posts               1.74   \n",
       "1                    Scott Walker               5.14   \n",
       "2                     Viral image               1.60   \n",
       "3                  Facebook posts               1.86   \n",
       "4         New York Citizens Audit               2.00   \n",
       "...                           ...                ...   \n",
       "4695    Freedom Defense Advocates               0.00   \n",
       "4696  Spike the Romney Attack Dog               8.00   \n",
       "4697        Log Cabin Republicans               8.00   \n",
       "4698                Sam Brownback               6.50   \n",
       "4699                   Obama Girl              10.00   \n",
       "\n",
       "                                         source_history  \n",
       "0     Instagram List of most-followed Instagram acco...  \n",
       "1     Scott Walker Scott Walker (politician) Scott W...  \n",
       "2     Viral phenomenon Imgur The dress Midjourney Da...  \n",
       "3     Facebook Facebook 3D Posts Meta Platforms Hist...  \n",
       "4     Sovereign citizen movement KPMG BNY Mellon Arc...  \n",
       "...                                                 ...  \n",
       "4695  United States Army Judge Advocate General's Co...  \n",
       "4696  Mitt Romney List of individual dogs January 6 ...  \n",
       "4697  Log Cabin Republicans Don Korotsky Norte Log C...  \n",
       "4698  Sam Brownback Kansas experiment Sam Brownback ...  \n",
       "4699  Amber Lee Ettinger Family of Barack Obama Mich...  \n",
       "\n",
       "[4700 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f4d46f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>source_history</th>\n",
       "      <th>mediacount</th>\n",
       "      <th>followees_to_followers_ratio</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>credibility_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>Scott Walker Scott Walker (politician) Scott W...</td>\n",
       "      <td>8683</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York Citizens Audit</td>\n",
       "      <td>Sovereign citizen movement KPMG BNY Mellon Arc...</td>\n",
       "      <td>1202</td>\n",
       "      <td>0.516274</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steve Kirsch</td>\n",
       "      <td>Steve Kirsch Stan Kirsch Against All Odds (198...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shannon Watts</td>\n",
       "      <td>Shannon Watts Watts family murders Shannon Wat...</td>\n",
       "      <td>431</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Larson</td>\n",
       "      <td>Chris Larson Chris Larson (disambiguation) Bri...</td>\n",
       "      <td>1138</td>\n",
       "      <td>0.200229</td>\n",
       "      <td>1</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                     source_history  \\\n",
       "0             Scott Walker  Scott Walker Scott Walker (politician) Scott W...   \n",
       "1  New York Citizens Audit  Sovereign citizen movement KPMG BNY Mellon Arc...   \n",
       "2             Steve Kirsch  Steve Kirsch Stan Kirsch Against All Odds (198...   \n",
       "3            Shannon Watts  Shannon Watts Watts family murders Shannon Wat...   \n",
       "4             Chris Larson  Chris Larson Chris Larson (disambiguation) Bri...   \n",
       "\n",
       "   mediacount  followees_to_followers_ratio  is_verified  credibility_score  \n",
       "0        8683                      0.003647            0               5.14  \n",
       "1        1202                      0.516274            1               2.00  \n",
       "2          10                      0.004475            1               0.80  \n",
       "3         431                      0.018288            0               6.00  \n",
       "4        1138                      0.200229            1               4.60  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "cred_reliability = pd.merge(merged_df, clean_df, on='source', how='inner').reset_index().drop(columns='index')\n",
    "cred_reliability['followees_to_followers_ratio'] = cred_reliability['followees'] / cred_reliability['followers'] + 1e-10\n",
    "cred_reliability = cred_reliability[['source', 'source_history', 'mediacount', 'followees_to_followers_ratio', 'is_verified', 'credibility_score']]\n",
    "cred_reliability = cred_reliability.dropna(subset=['source_history'])\n",
    "cred_reliability = cred_reliability.replace([np.inf, -np.inf], np.nan)\n",
    "cred_reliability = cred_reliability.dropna(subset=['followees_to_followers_ratio'])\n",
    "cred_reliability['is_verified'] = cred_reliability['is_verified'].apply(lambda x: 0 if x else 1)\n",
    "cred_reliability.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a84c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c09fcd97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
    "    tokens = nltk.word_tokenize(text)    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "cred_reliability['preprocessed_source'] = cred_reliability['source_history'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding(data):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "    \n",
    "    def get_bert_embeddings(data):\n",
    "        tokens = tokenizer(data.tolist(), padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = bert_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "        return embeddings\n",
    "\n",
    "    batch_size = 128\n",
    "    num_samples = len(data)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    embeddings_list = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = (i + 1) * batch_size\n",
    "        batch_data = data.iloc[start_idx:end_idx]\n",
    "        batch_embeddings = get_bert_embeddings(batch_data)\n",
    "        embeddings_list.append(batch_embeddings)\n",
    "\n",
    "    embeddings = torch.cat(embeddings_list, dim=0).cpu().numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cred_reliability['preprocessed_source']\n",
    "X = text_embedding(X)\n",
    "X = np.concatenate((X[:, :50], cred_reliability[['mediacount', 'followees_to_followers_ratio', 'is_verified']].values), axis=1)\n",
    "y = cred_reliability['credibility_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# X_additional_features_train = cred_reliability.loc[X_train.index, ['followees_to_followers_ratio', 'mediacount', 'is_verified']].values\n",
    "# X_additional_features_test = cred_reliability.loc[X_test.index, ['followees_to_followers_ratio', 'mediacount', 'is_verified']].values\n",
    "# X_train_tfidf_with_features = hstack((X_train_tfidf, X_additional_features_train))\n",
    "# X_test_tfidf_with_features = hstack((X_test_tfidf, X_additional_features_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    RandomForestRegressor(),\n",
    "    BayesianRidge(),\n",
    "]\n",
    "for model in models:\n",
    "    if model.__class__.__name__ != 'BayesianRidge':\n",
    "        model.fit(X_train_tfidf_with_features, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf_with_features)\n",
    "    else:    \n",
    "        model.fit(X_train_tfidf_with_features.toarray(), y_train)\n",
    "        y_pred = model.predict(X_test_tfidf_with_features.toarray())\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error for {model.__class__.__name__}: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba06df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
