{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c770587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae439de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd43c3b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9751417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_keywords = [\n",
    "    \"Conservatism\",\n",
    "    \"Moral order\",\n",
    "    \"Custom\",\n",
    "    \"Continuity\",\n",
    "    \"Prescription\",\n",
    "    \"Prudence\",\n",
    "    \"Variety\",\n",
    "    \"Property\",\n",
    "    \"Voluntary community\",\n",
    "    \"Restraints on power\",\n",
    "    \"Permanence\",\n",
    "    \"Progression\",\n",
    "    \"Change\",\n",
    "    \"Human nature\",\n",
    "    \"Liberty\",\n",
    "    \"Society\",\n",
    "    \"Order\",\n",
    "    \"Justice\",\n",
    "    \"Responsibility\",\n",
    "    \"Tradition\",\n",
    "    \"Community\",\n",
    "    \"Anarchy\",\n",
    "    \"Tyranny\",\n",
    "    \"Voluntarism\",\n",
    "    \"Individualism\",\n",
    "    \"Family\",\n",
    "    \"Equality\",\n",
    "    \"Property rights\",\n",
    "    \"Freedom\",\n",
    "    \"Decentralization\",\n",
    "    \"Conservatism vs. radicalism\",\n",
    "    \"Reconciliation\",\n",
    "    \"Balance\",\n",
    "    \"Permanence vs. Progression\",\n",
    "    \"Constitution\",\n",
    "    \"Checks and balances\",\n",
    "    \"Prudent reform\",\n",
    "    \"Stability\",\n",
    "    \"Continuity\",\n",
    "    \"Rationality\",\n",
    "    \"Diversity\",\n",
    "    \"Rights\",\n",
    "    \"Society's complexity\",\n",
    "    \"Oligarchy\",\n",
    "    \"Property ownership\",\n",
    "    \"Social institutions\",\n",
    "    \"Private possession\",\n",
    "    \"Private property\",\n",
    "    \"Human passions\",\n",
    "    \"Tension\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8acd46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "democracy_keywords = [\n",
    "    \"Participation\",\n",
    "    \"Democracy\",\n",
    "    \"Citizens\",\n",
    "    \"Direct democracy\",\n",
    "    \"Representative democracy\",\n",
    "    \"Citizen participation\",\n",
    "    \"Public debate\",\n",
    "    \"Town meetings\",\n",
    "    \"Peaceful protests\",\n",
    "    \"Civil society\",\n",
    "    \"Equality\",\n",
    "    \"Discrimination\",\n",
    "    \"Equal access\",\n",
    "    \"Voting\",\n",
    "    \"Accountability\",\n",
    "    \"Transparency\",\n",
    "    \"Corruption\",\n",
    "    \"Political tolerance\",\n",
    "    \"Minority rights\",\n",
    "    \"Multi-party system\",\n",
    "    \"Abuse of power\",\n",
    "    \"Free and fair elections\",\n",
    "    \"Freedom of economy\",\n",
    "    \"Bill of rights\",\n",
    "    \"Human rights\",\n",
    "    \"Free courts\",\n",
    "    \"Accepting election results\",\n",
    "    \"Rule of law\",\n",
    "    \"Government accountability\",\n",
    "    \"Independence of judiciary\",\n",
    "    \"Constitutional rights\",\n",
    "    \"Access to justice\",\n",
    "    \"Freedom of speech\",\n",
    "    \"Freedom of assembly\",\n",
    "    \"Economic freedom\",\n",
    "    \"Equal voting rights\",\n",
    "    \"Political debate\",\n",
    "    \"Government transparency\",\n",
    "    \"Public information\",\n",
    "    \"Judicial system\",\n",
    "    \"Dispute resolution\",\n",
    "    \"Peaceful transfer of power\",\n",
    "    \"Democratic process\",\n",
    "    \"Majority support\",\n",
    "    \"Equal application of laws\",\n",
    "    \"Liberties\",\n",
    "    \"Shadow report\",\n",
    "    \"EU\",\n",
    "    \"Rule of law situation\",\n",
    "    \"Member states\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7f37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_keywords = np.array([key.lower() for key in conservative_keywords])\n",
    "democracy_keywords = np.array([key.lower() for key in democracy_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093effa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dataset from: https://github.com/JerryWeiAI/NewB/blob/master/README.md\n",
    "f = open('political_affiliation_dataset.txt', 'r')\n",
    "X = []\n",
    "y = []\n",
    "for line in f.readlines():\n",
    "    X.append(line.split('\\t')[1])\n",
    "    y.append(int(line.split('\\t')[0]))\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ce43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is liberal, 1 is neutral, 2 is conservative\n",
    "def classify(x):\n",
    "    if x <= 4:\n",
    "        return 0\n",
    "    elif x >= 6:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "y = np.array(list(map(classify, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05eb7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_indices = np.where(y == 0)[0]\n",
    "label_1_indices = np.where(y == 1)[0]\n",
    "label_2_indices = np.where(y == 2)[0]\n",
    "\n",
    "num_samples_per_label = 5000\n",
    "\n",
    "selected_label_0_indices = np.random.choice(label_0_indices, num_samples_per_label, replace=False)\n",
    "selected_label_1_indices = np.random.choice(label_1_indices, num_samples_per_label, replace=False)\n",
    "selected_label_2_indices = np.random.choice(label_2_indices, num_samples_per_label, replace=False)\n",
    "\n",
    "selected_indices = np.concatenate((selected_label_0_indices, selected_label_1_indices, selected_label_2_indices))\n",
    "\n",
    "X_sample = X[selected_indices]\n",
    "y_sample = y[selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "985f8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_democratic_keyword(text):\n",
    "    for keyword in democracy_keywords:\n",
    "        if keyword.lower() in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "def contains_conservative_keyword(text):\n",
    "    for keyword in conservative_keywords:\n",
    "        if keyword.lower() in text.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8643b575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "democratic = [contains_democratic_keyword(text) for text in X_sample]\n",
    "sum(y_sample[democratic] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c842a7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conservative = [contains_conservative_keyword(text) for text in X_sample]\n",
    "sum(y_sample[conservative] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6050cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "encoded_sentences = [tokenizer.encode(text, add_special_tokens=True) for text in X_sample]\n",
    "labels = y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b45c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_set = [torch.LongTensor(text) for text in encoded_sentences]\n",
    "train_labels = list(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39f4f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation-test split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(encoded_set, train_labels, test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(test_texts, test_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33832600",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = pad_sequence(train_texts, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "train_dataset = TensorDataset(torch.LongTensor(train_texts), torch.LongTensor(train_labels))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185840f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a61f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d11a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids, labels=labels)\n",
    "        loss = loss_fn(output.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "382e1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = pad_sequence(val_texts, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "val_dataset = TensorDataset(torch.LongTensor(val_texts), torch.LongTensor(val_labels))\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cf14f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.45911111111111114\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    for batch in val_loader:\n",
    "        input_ids, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        output = model(input_ids)\n",
    "        labels = labels.to(device)\n",
    "        val_loss += loss_fn(output.logits, labels).item()\n",
    "        pred = output.logits.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "accuracy = correct / len(val_texts)\n",
    "print(f\"Valid accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "125b0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier = Nearest Neighbors, Score (test, accuracy) = 42.78, Training time = 1729.20 seconds\n",
    "#Classifier = Linear SVM, Score (test, accuracy) = 43.77, Training time = 57367.66 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d624e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy: 0.6268256803614585 with only 2 epochs\n",
    "# Sample test accuracy: 0.548 with 50 epochs, not equal size\n",
    "# Test accuracy: 0.5417777777777778 with 5000 samples of each"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
