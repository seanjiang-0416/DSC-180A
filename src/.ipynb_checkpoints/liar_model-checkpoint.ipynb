{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4209c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56b377",
   "metadata": {},
   "source": [
    "## Liar-Liar-Plus model\n",
    "This notebook is a hackathon on the Liar-Liar-Plus dataset. It combines some factors like credibility and political affiliation. It also did distillation by using pre-trained sentiment-scoring model to score the justification text and used as another factor in the model. The final model also included a Bert text-embedding of the statements which got truncated to the first 50 to lower its weight. The output contains a GridSearchCV and the best accuracy model and its parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file_path = '../data/LIAR-PLUS/dataset/tsv/train2.tsv'\n",
    "column_names = [\"index\", \"ID\", \"label\", \"statement\", \"subject\", 'speaker', 'speaker_job_title', 'state_info', 'party', 'barely_true_count', 'false_count', 'half_true_count', 'mostly_true_count', 'pants_on_fire_count', 'context', 'justification']\n",
    "train_df = pd.read_csv(tsv_file_path, sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911ca1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file_path = '../data/LIAR-PLUS/dataset/tsv/val2.tsv'\n",
    "column_names = [\"index\", \"ID\", \"label\", \"statement\", \"subject\", 'speaker', 'speaker_job_title', 'state_info', 'party', 'barely_true_count', 'false_count', 'half_true_count', 'mostly_true_count', 'pants_on_fire_count', 'context', 'justification'] \n",
    "val_df = pd.read_csv(tsv_file_path, sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0b4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file_path = '../data/LIAR-PLUS/dataset/tsv/test2.tsv'\n",
    "column_names = [\"index\", \"ID\", \"label\", \"statement\", \"subject\", 'speaker', 'speaker_job_title', 'state_info', 'party', 'barely_true_count', 'false_count', 'half_true_count', 'mostly_true_count', 'pants_on_fire_count', 'context', 'justification'] \n",
    "test_df = pd.read_csv(tsv_file_path, sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce7e436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10242, 16), (1284, 16), (1267, 16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3da4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_name(name):\n",
    "    if isinstance(name, str):\n",
    "        parts = name.split('-')\n",
    "        formatted_name = ' '.join(part.capitalize() for part in parts)\n",
    "        return formatted_name\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "train_df['speaker'] = train_df['speaker'].apply(format_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5bc8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_df = pd.read_csv('../data/credibility.csv').drop(columns = 'Unnamed: 0').drop_duplicates(subset='source')\n",
    "merged_df = pd.merge(train_df, cred_df, left_on='speaker', right_on='source', how='left').drop_duplicates()\n",
    "# Impute credibility score with historical data in this dataset, no true count\n",
    "standard = ['mostly_true_count','half_true_count', 'barely_true_count','false_count','pants_on_fire_count']\n",
    "score = np.array([8, 6, 4, 2, 0])\n",
    "proportions = merged_df[standard].div(merged_df[standard].sum(axis=1), axis=0)\n",
    "weighted_values = proportions * score\n",
    "merged_df['credibility_score'] = merged_df['credibility_score'].fillna(weighted_values.sum(axis=1))\n",
    "merged_df['party'] = merged_df['party'].replace(np.nan, 'none')\n",
    "merged_df['statement'] = merged_df['statement'].replace(np.nan, 'none')\n",
    "merged_df = merged_df.dropna(subset=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40a8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 20:41:34.373444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "def sentimentize_just(merged_df):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    distilled_student_sentiment_classifier = pipeline(\n",
    "        model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "        return_all_scores=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    scale = {\n",
    "        'positive': 1,\n",
    "        'neutral': 0,\n",
    "        'negative': -1\n",
    "    }\n",
    "\n",
    "    def sentiment_score(result):\n",
    "        numerical_scores = [scale[sentiment['label']] * sentiment['score'] for sentiment in result[0]]\n",
    "        overall_score = sum(numerical_scores)\n",
    "        return overall_score\n",
    "\n",
    "    def sentiment_shift(article):\n",
    "        cleaned_text = re.sub(r'\\\\', '', article)\n",
    "        cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Replace multiple spaces with a single space\n",
    "        cleaned_text = cleaned_text.encode('ascii', 'ignore').decode('utf-8')\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "        cleaned_text = re.sub(r'“|”', '\"', cleaned_text)\n",
    "\n",
    "        data = []\n",
    "        sentences = sent_tokenize(article)\n",
    "        for sentence in sentences:\n",
    "            # For now, trim sentence if longer than 512\n",
    "            if len(sentence) > 512:\n",
    "                sentence = sentence[:512]\n",
    "            result = sentiment_score(distilled_student_sentiment_classifier(sentence))\n",
    "            data.append(result)\n",
    "        return data\n",
    "\n",
    "    result = []\n",
    "    for i in range(merged_df.shape[0]):\n",
    "        just = merged_df.iloc[i]['justification']\n",
    "        if isinstance(just, float) and math.isnan(just):\n",
    "            result.append([0])\n",
    "            continue\n",
    "        result.append(sentiment_shift(just))\n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration {i} is done')\n",
    "            clear_output(wait=True)\n",
    "    just_sent = [np.mean(lst) for lst in result]\n",
    "    return just_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9238b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
    "    tokens = nltk.word_tokenize(text)    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b5dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10200 is done\n"
     ]
    }
   ],
   "source": [
    "merged_df['sentiment_just'] = sentimentize_just(merged_df)\n",
    "merged_df['statement'] = merged_df['statement'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488f7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4568/2795716764.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['party'] = X_train['party'].apply(map_party)\n"
     ]
    }
   ],
   "source": [
    "party_mapping = {\n",
    "    'republican': 0,\n",
    "    'democrat': 1,\n",
    "}\n",
    "\n",
    "# Define a function to apply the mapping\n",
    "def map_party(label):\n",
    "    return party_mapping.get(label, 2)  # If label is not in the mapping, return the original label\n",
    "X_train = merged_df[['statement', 'party', 'sentiment_just', 'credibility_score']]\n",
    "y_train = merged_df['label']\n",
    "X_train['party'] = X_train['party'].apply(map_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193baa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4568/4262729945.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['party'] = X_val['party'].apply(map_party)\n"
     ]
    }
   ],
   "source": [
    "# Transforming validation set in the same way as training data\n",
    "def transform_val(test_df):\n",
    "    test_df['speaker'] = test_df['speaker'].apply(format_name)\n",
    "    cred_df = pd.read_csv('../data/credibility.csv').drop(columns = 'Unnamed: 0').drop_duplicates(subset='source')\n",
    "    merged_df = pd.merge(test_df, cred_df, left_on='speaker', right_on='source', how='left').drop_duplicates()\n",
    "    # Impute credibility score with historical data in this dataset, no true count\n",
    "    standard = ['mostly_true_count','half_true_count', 'barely_true_count','false_count','pants_on_fire_count']\n",
    "    score = np.array([8, 6, 4, 2, 0])\n",
    "    proportions = merged_df[standard].div(merged_df[standard].sum(axis=1), axis=0)\n",
    "    weighted_values = proportions * score\n",
    "    merged_df['credibility_score'] = merged_df['credibility_score'].fillna(weighted_values.sum(axis=1))\n",
    "    merged_df['party'] = merged_df['party'].replace(np.nan, 'none')\n",
    "    merged_df['statement'] = merged_df['statement'].replace(np.nan, 'none')\n",
    "    merged_df = merged_df.dropna(subset=['label'])\n",
    "    merged_df['statement'] = merged_df['statement'].apply(preprocess_text)\n",
    "    merged_df['sentiment_just'] = sentimentize_just(merged_df)\n",
    "    return merged_df\n",
    "merged_val = transform_val(val_df)\n",
    "X_val = merged_val[['statement', 'party', 'sentiment_just', 'credibility_score']]\n",
    "X_val['party'] = X_val['party'].apply(map_party)\n",
    "y_val = merged_val['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48863825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4568/1595149544.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['party'] = X_test['party'].apply(map_party)\n"
     ]
    }
   ],
   "source": [
    "# Transforming test set in the same way as training data\n",
    "def transform_test(test_df):\n",
    "    test_df['speaker'] = test_df['speaker'].apply(format_name)\n",
    "    cred_df = pd.read_csv('../data/credibility.csv').drop(columns = 'Unnamed: 0').drop_duplicates(subset='source')\n",
    "    merged_df = pd.merge(test_df, cred_df, left_on='speaker', right_on='source', how='left').drop_duplicates()\n",
    "    # Impute credibility score with historical data in this dataset, no true count\n",
    "    standard = ['mostly_true_count','half_true_count', 'barely_true_count','false_count','pants_on_fire_count']\n",
    "    score = np.array([8, 6, 4, 2, 0])\n",
    "    proportions = merged_df[standard].div(merged_df[standard].sum(axis=1), axis=0)\n",
    "    weighted_values = proportions * score\n",
    "    merged_df['credibility_score'] = merged_df['credibility_score'].fillna(weighted_values.sum(axis=1))\n",
    "    merged_df['party'] = merged_df['party'].replace(np.nan, 'none')\n",
    "    merged_df['statement'] = merged_df['statement'].replace(np.nan, 'none')\n",
    "    merged_df = merged_df.dropna(subset=['label'])\n",
    "    merged_df['statement'] = merged_df['statement'].apply(preprocess_text)\n",
    "    merged_df['sentiment_just'] = sentimentize_just(merged_df)\n",
    "    return merged_df\n",
    "merged_test = transform_test(test_df)\n",
    "X_test = merged_test[['statement', 'party', 'sentiment_just', 'credibility_score']]\n",
    "X_test['party'] = X_test['party'].apply(map_party)\n",
    "y_test = merged_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc168a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data to save time and GPU\n",
    "merged_df.to_csv('../data/processsed_liar_train.csv', index = None)\n",
    "merged_test.to_csv('../data/processsed_liar_test.csv', index = None)\n",
    "merged_val.to_csv('../data/processsed_liar_val.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dce170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4568/118981035.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['party'] = X_train['party'].apply(map_party)\n",
      "/tmp/ipykernel_4568/118981035.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['party'] = X_val['party'].apply(map_party)\n",
      "/tmp/ipykernel_4568/118981035.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['party'] = X_test['party'].apply(map_party)\n"
     ]
    }
   ],
   "source": [
    "party_mapping = {\n",
    "    'republican': 0,\n",
    "    'democrat': 1,\n",
    "}\n",
    "\n",
    "# Define a function to apply the mapping\n",
    "def map_party(label):\n",
    "    return party_mapping.get(label, 2)\n",
    "\n",
    "# Train set\n",
    "merged_df = pd.read_csv('../data/processsed_liar_train.csv')\n",
    "X_train = merged_df[['statement', 'party', 'sentiment_just', 'credibility_score']]\n",
    "y_train = merged_df['label']\n",
    "X_train['party'] = X_train['party'].apply(map_party)\n",
    "X_train = X_train.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Validation set\n",
    "merged_val = pd.read_csv('../data/processsed_liar_val.csv')\n",
    "X_val = merged_val[['statement', 'party', 'sentiment_just', 'credibility_score']]\n",
    "X_val['party'] = X_val['party'].apply(map_party)\n",
    "X_val = X_val.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "y_val = merged_val['label']\n",
    "\n",
    "# Test set\n",
    "merged_test = pd.read_csv('../data/processsed_liar_test.csv')\n",
    "X_test = merged_test[['statement', 'party', 'sentiment_just', 'credibility_score']]\n",
    "X_test['party'] = X_test['party'].apply(map_party)\n",
    "X_test = X_test.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "y_test = merged_test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b051e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "import torch\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "def get_bert_embeddings(data):\n",
    "    tokens = tokenizer(data['statement'].tolist(), padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = bert_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Can change to 128 or other batch size\n",
    "batch_size = 64\n",
    "num_samples = len(X_train)\n",
    "num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "X_train_embeddings_list = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    batch_data = X_train.iloc[start_idx:end_idx]\n",
    "    batch_embeddings = get_bert_embeddings(batch_data)\n",
    "    X_train_embeddings_list.append(batch_embeddings)\n",
    "\n",
    "X_train_embeddings = torch.cat(X_train_embeddings_list, dim=0).cpu().numpy()\n",
    "\n",
    "# Preprocess val set\n",
    "def process_val_data(data):\n",
    "    tokens = tokenizer(data['statement'].tolist(), padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = bert_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "num_samples_val = len(X_val)\n",
    "num_batches_val = (num_samples_val + batch_size - 1) // batch_size\n",
    "\n",
    "X_val_embeddings_list = []\n",
    "\n",
    "for i in range(num_batches_val):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    batch_data = X_val.iloc[start_idx:end_idx]\n",
    "    batch_embeddings = process_val_data(batch_data)\n",
    "    X_val_embeddings_list.append(batch_embeddings)\n",
    "\n",
    "X_val_embeddings = torch.cat(X_val_embeddings_list, dim=0).cpu().numpy()\n",
    "\n",
    "# Preprocess test set\n",
    "def process_test_data(data):\n",
    "    tokens = tokenizer(data['statement'].tolist(), padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = bert_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "num_samples_test = len(X_test)\n",
    "num_batches_test = (num_samples_test + batch_size - 1) // batch_size\n",
    "\n",
    "X_test_embeddings_list = []\n",
    "\n",
    "for i in range(num_batches_test):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    batch_data = X_test.iloc[start_idx:end_idx]\n",
    "    batch_embeddings = process_test_data(batch_data)\n",
    "    X_test_embeddings_list.append(batch_embeddings)\n",
    "\n",
    "X_test_embeddings = torch.cat(X_test_embeddings_list, dim=0).cpu().numpy()\n",
    "\n",
    "X_train_combined = np.concatenate((X_train_embeddings[:, :50], X_train[['party', 'sentiment_just', 'credibility_score']].values), axis=1)\n",
    "X_val_combined = np.concatenate((X_val_embeddings[:, :50], X_val[['party', 'sentiment_just', 'credibility_score']].values), axis=1)\n",
    "X_test_combined = np.concatenate((X_test_embeddings[:, :50], X_test[['party', 'sentiment_just', 'credibility_score']].values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b7058b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with Best Parameters: {'n_estimators': 200},and Accuracy: 0.3909657320872274 on validation\n",
      "RandomForest with Accuracy: 0.36937647987371747 on test\n",
      "GradientBoosting with Best Parameters: {'n_estimators': 100},and Accuracy: 0.39953271028037385 on validation\n",
      "GradientBoosting with Accuracy: 0.3709550118389897 on test\n",
      "SVM with Best Parameters: {'C': 10, 'kernel': 'rbf'},and Accuracy: 0.39797507788161995 on validation\n",
      "SVM with Accuracy: 0.3756906077348066 on test\n",
      "Best Model - Accuracy: 0.39953271028037385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifiers = {\n",
    "    'RandomForest': (RandomForestClassifier(), {'n_estimators': [50, 100, 200]}),\n",
    "    'GradientBoosting': (GradientBoostingClassifier(), {'n_estimators': [50, 100, 200]}),\n",
    "    'SVM': (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']})\n",
    "}\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "for name, (classifier, param_grid) in classifiers.items():\n",
    "    clf = GridSearchCV(classifier, param_grid, cv=3, scoring='accuracy')\n",
    "    clf.fit(X_train_combined, y_train)\n",
    "    y_pred = clf.predict(X_val_combined)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f'{name} with Best Parameters: {clf.best_params_},and Accuracy: {accuracy} on validation')\n",
    "    \n",
    "    y_pred_test = clf.predict(X_test_combined)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f'{name} with Accuracy: {accuracy_test} on test')\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = clf.best_estimator_\n",
    "y_pred_best = best_model.predict(X_val_combined)\n",
    "accuracy_best = accuracy_score(y_val, y_pred_best)\n",
    "print(f'Best Model - Accuracy: {accuracy_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328af9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3709550118389897"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = best_model.predict(X_test_combined)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_test)\n",
    "accuracy_best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
